{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn, warnings \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, confusion_matrix\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:95% !important; }</style>\")\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boolean_relationship</th>\n",
       "      <th>all_info</th>\n",
       "      <th>chemical_name</th>\n",
       "      <th>disease_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>describe yearold woman preexisting mitral valv...</td>\n",
       "      <td>caffeine</td>\n",
       "      <td>ventricular fibrillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>laxation critically ill patients lactulose pol...</td>\n",
       "      <td>lactulose</td>\n",
       "      <td>critically ill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>methotrexate mtx sulfasalazine ssz cyclosporin...</td>\n",
       "      <td>sulfasalazine/SSZ</td>\n",
       "      <td>PsA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>polychlorinated biphenyls pcbs persistent envi...</td>\n",
       "      <td>Polychlorinated biphenyls/PCBs</td>\n",
       "      <td>NAFLD/non-alcoholic fatty liver disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>although pcp classified human carcinogen epide...</td>\n",
       "      <td>PCP</td>\n",
       "      <td>sarcoma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  boolean_relationship                                           all_info  \\\n",
       "0                 True  describe yearold woman preexisting mitral valv...   \n",
       "1                False  laxation critically ill patients lactulose pol...   \n",
       "2                False  methotrexate mtx sulfasalazine ssz cyclosporin...   \n",
       "3                 True  polychlorinated biphenyls pcbs persistent envi...   \n",
       "4                 True  although pcp classified human carcinogen epide...   \n",
       "\n",
       "                    chemical_name                             disease_name  \n",
       "0                        caffeine                 ventricular fibrillation  \n",
       "1                       lactulose                           critically ill  \n",
       "2               sulfasalazine/SSZ                                      PsA  \n",
       "3  Polychlorinated biphenyls/PCBs  NAFLD/non-alcoholic fatty liver disease  \n",
       "4                             PCP                                  sarcoma  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labeled = pd.read_csv('data/labeled_df.csv', na_values=['?'])\n",
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df_labeled.boolean_relationship\n",
    "X = df_labeled.all_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize\n",
    "\n",
    "#### Finding the optimal number of features. We will solve the following as a Explore then exploit Multi-armed bandit problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 100.000000: 0.701244813278\n",
      "Accuracy of 1000.000000: 0.738589211618\n",
      "Accuracy of 3000.000000: 0.759336099585\n",
      "Accuracy of 5800.000000: 0.763485477178\n",
      "Accuracy of 6000.000000: 0.763485477178\n",
      "Accuracy of 7000.000000: 0.767634854772\n",
      "Accuracy of 7300.000000: 0.769709543568\n",
      "Accuracy of 7500.000000: 0.769709543568\n",
      "Accuracy of 7800.000000: 0.769709543568\n",
      "Accuracy of 8000.000000: 0.767634854772\n"
     ]
    }
   ],
   "source": [
    "for features in [100,1000,3000,5800,6000,7000,7300,7500,7800,8000]:\n",
    "    tf_idf = TfidfVectorizer(analyzer='word', stop_words='english',max_features=features)\n",
    "    X_tf = tf_idf.fit_transform(X).toarray()    \n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_tf, y, random_state=1)\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_tr, y_tr)\n",
    "    print('Accuracy of %f:' %features, mnb.score(X_te, y_te))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 100.000000: 0.697095435685\n",
      "Accuracy of 1000.000000: 0.742738589212\n",
      "Accuracy of 3000.000000: 0.761410788382\n",
      "Accuracy of 5800.000000: 0.759336099585\n",
      "Accuracy of 6000.000000: 0.761410788382\n",
      "Accuracy of 7000.000000: 0.761410788382\n",
      "Accuracy of 7300.000000: 0.761410788382\n",
      "Accuracy of 7500.000000: 0.761410788382\n",
      "Accuracy of 7800.000000: 0.761410788382\n",
      "Accuracy of 8000.000000: 0.761410788382\n"
     ]
    }
   ],
   "source": [
    "#finding the optimal number of features \n",
    "X = df_labeled.all_info\n",
    "for features in [100,1000,3000,5800,6000,7000,7300,7500,7800,8000]:\n",
    "    tf_idf = TfidfVectorizer(analyzer='word', stop_words='english',max_features=features, sublinear_tf=True)\n",
    "    X_tf = tf_idf.fit_transform(X).toarray()    \n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_tf, y, random_state=1)\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_tr, y_tr)\n",
    "    print('Accuracy of %f:' %features, mnb.score(X_te, y_te))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 100.000000: 0.697095435685\n",
      "Accuracy of 1000.000000: 0.740663900415\n",
      "Accuracy of 3000.000000: 0.761410788382\n",
      "Accuracy of 5800.000000: 0.757261410788\n",
      "Accuracy of 6000.000000: 0.759336099585\n",
      "Accuracy of 7000.000000: 0.761410788382\n",
      "Accuracy of 7300.000000: 0.761410788382\n",
      "Accuracy of 7500.000000: 0.761410788382\n",
      "Accuracy of 7800.000000: 0.761410788382\n",
      "Accuracy of 8000.000000: 0.761410788382\n"
     ]
    }
   ],
   "source": [
    "#finding the optimal number of features \n",
    "X = df_labeled.all_info\n",
    "for features in [100,1000,3000,5800,6000,7000,7300,7500,7800,8000]:\n",
    "    tf_idf = TfidfVectorizer(analyzer='word', stop_words='english',max_features=features, smooth_idf = False, sublinear_tf=True)\n",
    "    X_tf = tf_idf.fit_transform(X).toarray()    \n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_tf, y, random_state=1)\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_tr, y_tr)\n",
    "    print('Accuracy of %f:' %features, mnb.score(X_te, y_te))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 100.000000: 0.697095435685\n",
      "Accuracy of 1000.000000: 0.740663900415\n",
      "Accuracy of 3000.000000: 0.761410788382\n",
      "Accuracy of 5800.000000: 0.757261410788\n",
      "Accuracy of 6000.000000: 0.759336099585\n",
      "Accuracy of 7000.000000: 0.761410788382\n",
      "Accuracy of 7300.000000: 0.761410788382\n",
      "Accuracy of 7500.000000: 0.761410788382\n",
      "Accuracy of 7800.000000: 0.761410788382\n",
      "Accuracy of 8000.000000: 0.761410788382\n"
     ]
    }
   ],
   "source": [
    "#finding the optimal number of features \n",
    "X = df_labeled.all_info\n",
    "for features in [100,1000,3000,5800,6000,7000,7300,7500,7800,8000]:\n",
    "    tf_idf = TfidfVectorizer(analyzer='word', stop_words='english',max_features=features, smooth_idf = False, sublinear_tf=True)\n",
    "    X_tf = tf_idf.fit_transform(X).toarray()    \n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X_tf, y, random_state=1)\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(X_tr, y_tr)\n",
    "    print('Accuracy of %f:' %features, mnb.score(X_te, y_te))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We will use: **7500 features with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try out different vectorizers:  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \n",
    "                             stop_words = 'english',   \n",
    "                             max_features = 7500)\n",
    "tfidf = TfidfVectorizer(analyzer='word', \n",
    "                        stop_words='english', \n",
    "                        max_features=7500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the model and learns the vocabulary; and transform training data into feature vectors. \n",
    "\n",
    "#COUNT VECTORIZER\n",
    "X0 = vectorizer.fit_transform(X).toarray()\n",
    "X_train0, X_test0, y_train0, y_test0 = train_test_split(X0, y, random_state=1)\n",
    "\n",
    "#TF-IDF VECTORIZER (normalizes the vocabulary)\n",
    "X = tfidf.fit_transform(X).toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes \n",
    "\n",
    "#### Comparing results of CountVectorizer and TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Accuracy: 74.69%\n",
      "TF-IDF Accuracy: 74.69%\n"
     ]
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train0, y_train0)\n",
    "print('Count Accuracy: %.2f%%' %(bnb.score(X_test0, y_test0)*100))\n",
    "\n",
    "bnb.fit(X_train, y_train)\n",
    "print('TF-IDF Accuracy: %.2f%%' %(bnb.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Accuracy: 74.27%\n",
      "TF-IDF Accuracy: 76.97%\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train0, y_train0)\n",
    "print('Count Accuracy: %.2f%%' %(mnb.score(X_test0, y_test0)*100))\n",
    "\n",
    "mnb.fit(X_train, y_train)\n",
    "print('TF-IDF Accuracy: %.2f%%' %(mnb.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Accuracy: 68.26%\n",
      "TF-IDF Accuracy: 68.26%\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train0, y_train0)\n",
    "print('Count Accuracy: %.2f%%' %(gnb.score(X_test0, y_test0)*100))\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "print('TF-IDF Accuracy: %.2f%%' %(gnb.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomical NB had a higher accuracy than Bernoulli Naive Bayes, because my feature vectors are binary. Let us try this with other classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try other classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random forest Count Accuracy: 73.44%\n",
      "random forest TF-IDF Accuracy: 72.41%\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train0, y_train0)\n",
    "print(\"random forest Count Accuracy: %.2f%%\" %(rf.score(X_test0, y_test0)*100))\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"random forest TF-IDF Accuracy: %.2f%%\" %(rf.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn Count Accuracy: 62.66%\n",
      "knn TF-IDF Accuracy: 68.26%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train0, y_train0)\n",
    "print(\"knn Count Accuracy: %.2f%%\" %(knn.score(X_test0, y_test0)*100))\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"knn TF-IDF Accuracy: %.2f%%\" %(knn.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic Count Accuracy: 74.07%\n",
      "logistic TF-IDF Accuracy: 76.97%\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(X_train0, y_train0)\n",
    "print(\"logistic Count Accuracy: %.2f%%\" %(log.score(X_test0, y_test0)*100))\n",
    "\n",
    "log.fit(X_train, y_train)\n",
    "print(\"logistic TF-IDF Accuracy: %.2f%%\" %(log.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaboost Count Accuracy: 70.75%\n",
      "adaboost TF-IDF Accuracy: 71.99%\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train0, y_train0)\n",
    "print(\"adaboost Count Accuracy: %.2f%%\" %(ada.score(X_test0, y_test0)*100))\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "print(\"adaboost TF-IDF Accuracy: %.2f%%\" %(ada.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmSVC Count Accuracy: 69.71%\n",
      "svmSVC TF-IDF Accuracy: 49.38%\n",
      "\n",
      "svmNuSVC Count Accuracy: 74.90%\n",
      "svmNuSVC TF-IDF Accuracy: 73.44%\n",
      "\n",
      "svmLinear Count Accuracy: 72.82%\n",
      "svmLinear TF-IDF Accuracy: 75.52%\n"
     ]
    }
   ],
   "source": [
    "svmSVC = svm.SVC() \n",
    "svmSVC.fit(X_train0, y_train0)\n",
    "print(\"svmSVC Count Accuracy: %.2f%%\" %(svmSVC.score(X_test0, y_test0)*100))\n",
    "\n",
    "svmSVC.fit(X_train, y_train) \n",
    "print(\"svmSVC TF-IDF Accuracy: %.2f%%\" %(svmSVC.score(X_test, y_test)*100),end=\"\\n\\n\")\n",
    "\n",
    "svmNuSVC = svm.NuSVC() \n",
    "svmNuSVC.fit(X_train0, y_train0)\n",
    "print(\"svmNuSVC Count Accuracy: %.2f%%\" %(svmNuSVC.score(X_test0, y_test0)*100))\n",
    "\n",
    "svmNuSVC.fit(X_train, y_train) \n",
    "print(\"svmNuSVC TF-IDF Accuracy: %.2f%%\" %(svmNuSVC.score(X_test, y_test)*100),end=\"\\n\\n\")\n",
    "\n",
    "svmLinear = svm.LinearSVC()\n",
    "svmLinear.fit(X_train0, y_train0)\n",
    "print(\"svmLinear Count Accuracy: %.2f%%\" %(svmLinear.score(X_test0, y_test0)*100))\n",
    "\n",
    "svmLinear.fit(X_train, y_train) \n",
    "print(\"svmLinear TF-IDF Accuracy: %.2f%%\" %(svmLinear.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression, Multinomial Bayes, and svmLinear seem to outperform the other classifiers with TF-IDF. We will tune their hyperparameters..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tune hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'fit_prior': True, 'alpha': 1.0099999999999996}\n"
     ]
    }
   ],
   "source": [
    "mnb_grid = {'alpha': list(np.arange(0.1,1.1,0.01)),\n",
    "            'fit_prior': [True, False],\n",
    "            }\n",
    "\n",
    "mnb_gridsearch = GridSearchCV(MultinomialNB(),\n",
    "                             mnb_grid,\n",
    "                             n_jobs=-1,\n",
    "                             cv=5,\n",
    "                             scoring='f1_weighted')\n",
    "mnb_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", mnb_gridsearch.best_params_)\n",
    "\n",
    "best_mnb_model = mnb_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB accuracy before tuning: 76.97%\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "print('MultinomialNB accuracy before tuning: %.2f%%' %(mnb.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB accuracy after tuning: 76.97%\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(fit_prior=True,alpha=1.0)\n",
    "mnb.fit(X_train, y_train)\n",
    "print('MultinomialNB accuracy after tuning: %.2f%%' %(mnb.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is strange because the accuracy decreased after tuning the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'fit_intercept': True, 'C': 0.49999999999999978, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "log_grid = {'penalty': ['l1','l2'],\n",
    "            'C': list(np.arange(0.1,1.1,0.01)),\n",
    "            'fit_intercept': [True, False]\n",
    "            }\n",
    "\n",
    "log_gridsearch = GridSearchCV(LogisticRegression(),\n",
    "                             log_grid,\n",
    "                             n_jobs=-1,\n",
    "                             cv=5,\n",
    "                             scoring='f1_weighted')\n",
    "log_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", log_gridsearch.best_params_)\n",
    "\n",
    "best_log_model = log_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'fit_intercept': True, 'C': 0.48999999999999977, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "log_grid = {'penalty': ['l2'],\n",
    "            'C': list(np.arange(0.1,1.1,0.01)),\n",
    "            'fit_intercept': [True, False],\n",
    "            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag']\n",
    "            }\n",
    "\n",
    "log_gridsearch = GridSearchCV(LogisticRegression(),\n",
    "                             log_grid,\n",
    "                             n_jobs=-1,\n",
    "                             cv=5,\n",
    "                             scoring='f1_weighted')\n",
    "log_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", log_gridsearch.best_params_)\n",
    "\n",
    "best_log_model = log_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic accuracy before tuning: 76.97%\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)\n",
    "print(\"logistic accuracy before tuning: %.2f%%\" %(log.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic accuracy after tuning: 77.39%\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression(fit_intercept=True, solver='newton-cg',C=0.48999999999999977, penalty='l2')\n",
    "log.fit(X_train, y_train)\n",
    "print(\"logistic accuracy after tuning: %.2f%%\" %(log.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_grid = {'C': list(np.linspace(.001,1000, endpoint=True)),\n",
    "            #'loss': ['hinge','squared_hinge'], \n",
    "            #'penalty': ['l1'],\n",
    "            'dual': [True, False],\n",
    "            'multi_class': ['ovr','crammer_singer'],\n",
    "            'fit_intercept':[True, False],\n",
    "            'class_weight':[None,'balanced']\n",
    "            }\n",
    "\n",
    "svm_gridsearch = GridSearchCV(svm.LinearSVC(),\n",
    "                             svm_grid,\n",
    "                             n_jobs=-1,\n",
    "                             cv=5,\n",
    "                             scoring='f1_weighted')\n",
    "svm_gridsearch.fit(X_train, y_train)\n",
    "\n",
    "print(\"best parameters:\", svm_gridsearch.best_params_)\n",
    "\n",
    "best_svm_model = svm_gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmLinear = svm.LinearSVC()\n",
    "svmLinear.fit(X_train, y_train) \n",
    "print(\"svmLinear accuracy before tuning: %.2f%%\" %(svmLinear.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svmLinear = svm.LinearSVC(dual=True, fit_intercept=False,C=0.001, class_weight='balanced', multi_class='ovr')\n",
    "svmLinear.fit(X_train, y_train) \n",
    "print(\"svmLinear accuracy after tuning: %.2f%%\" %(svmLinear.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression gives us the most accurate predictions, because it puts weights on the most unique features, unlike Multinomial Bayes, which assumes that all features are independent.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roc Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = log.decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_score=predictions, y_true=y_test)\n",
    "\n",
    "x = [0.0,1.0]\n",
    "plt.plot(x,x, color = 'red')\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity, Recall)\")\n",
    "plt.title(\"ROC plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, log.predict(X_test))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(normalized_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    #plt.xticks(2, ('True', 'False'), rotation=45)\n",
    "    #plt.yticks(2, ('True', 'False'))\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(normalized_cm, title = \"Normalized Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Fitting Logistic regression to Ridge increased its' accuracy. In Ridge, the coefficients of the linear transformation are normally distributed. In Lasso they are Laplace distributed. Generally, when you have many small/medium sized effects you should go with ridge. If you have only a few variables with a medium/large effect, go with lasso, as demonstrated above. \n",
    "\n",
    "Also, based on the Roc Curve and Confusion Matrices, we are able to determine whether a chemical causes a disease based on the words from the abstracts on PubMed and the other words that were in the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
